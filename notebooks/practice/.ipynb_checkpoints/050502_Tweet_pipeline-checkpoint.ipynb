{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04d737e6",
   "metadata": {},
   "source": [
    "# Tweet pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7596622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:01.493727Z",
     "start_time": "2021-06-08T03:37:01.472963Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/efraflores/Desktop/hub/diplo/venv/lib/python3.9/site-packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67714952",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evironment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8184ab1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:03.254473Z",
     "start_time": "2021-06-08T03:37:01.504396Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from pickle import load\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from unicodedata import normalize\n",
    "from numpy import append,zeros,array\n",
    "from re import sub, UNICODE, findall\n",
    "from pandas import read_csv,DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b48ca",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec70f438",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fcb996e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:03.275089Z",
     "start_time": "2021-06-08T03:37:03.261492Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BASE_DIR = '/Users/efraflores/Desktop/EF/Diplo/data/05'\n",
    "FILE_NAME = '0505_tuit.csv'\n",
    "MODEL_SUP = 'tuit_model_supervised.pickle'\n",
    "MODEL_UNSUP = 'tuit_model_unsupervised.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea08b4b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997ae4ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:05.401818Z",
     "start_time": "2021-06-08T03:37:03.286180Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date_created</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>language</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1033768043766312960</th>\n",
       "      <td>2018-08-26T17:28:02.960000</td>\n",
       "      <td>@edwikk @ChelseaFC @marcosalonso03 Sot ka qen ...</td>\n",
       "      <td>es</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>{\"Neutral\":0.88814127445220947265625,\"Negative...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             tweet_date_created  \\\n",
       "tweet_id                                          \n",
       "1033768043766312960  2018-08-26T17:28:02.960000   \n",
       "\n",
       "                                                            tweet_text  \\\n",
       "tweet_id                                                                 \n",
       "1033768043766312960  @edwikk @ChelseaFC @marcosalonso03 Sot ka qen ...   \n",
       "\n",
       "                    language sentiment  \\\n",
       "tweet_id                                 \n",
       "1033768043766312960       es   NEUTRAL   \n",
       "\n",
       "                                                       sentiment_score  \n",
       "tweet_id                                                                \n",
       "1033768043766312960  {\"Neutral\":0.88814127445220947265625,\"Negative...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_csv(path.join(BASE_DIR,FILE_NAME),encoding='latin').set_index('tweet_id')\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b5fcee",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd25d5a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Clean tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859df28e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:05.422678Z",
     "start_time": "2021-06-08T03:37:05.408647Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def clean_tweet(text):\n",
    "    text = normalize('NFD', text).encode('ascii', 'ignore')\n",
    "    text = sub(\"[^a-zA-Z'\\s]\",' ',text.decode('utf-8'),flags=UNICODE)\n",
    "    # Eliminación de las menciones en los tweets. Se excluyen los @ junto con todos los caracteres que le siguen (De la A a la Z, en minúsculas y mayusculas, y números del 0 al 9)\n",
    "    text = sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "    # Eliminación de las menciones en los tweets. Se excluyen los # junto con todos los caracteres que le siguen (De la A a la Z, en minúsculas y mayusculas, y números del 0 al 9)\n",
    "    text = sub(r\"#[A-Za-z0-9]+\", ' ', text)\n",
    "    # Eliminación de los links que inicien con https o http. Inicamos que la s es opcional (s?).\n",
    "    text = sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "    # Eliminación de los links que inicien con www.\n",
    "    text = sub(r\"www.[A-Za-z0-9./]+\", ' ', text)\n",
    "    # Eliminación de todos los catacteres menos las letras y signos de puntuación. \n",
    "    text = sub(r\"[^a-zA-Z]\", ' ', text)\n",
    "    #Elimina caracteres múltiples\n",
    "    text = sub(r'(\\S)\\1*',r'\\1',text)\n",
    "    # Eliminamos espacios en blanco dobles.\n",
    "    text = sub(r\" +\", ' ', text)\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e42071",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Read models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84cf70d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:05.438583Z",
     "start_time": "2021-06-08T03:37:05.428007Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def read_models():\n",
    "    with open(path.join(BASE_DIR,MODEL_SUP), 'rb') as f: \n",
    "        model_sup = load(f)\n",
    "\n",
    "    with open(path.join(BASE_DIR,MODEL_UNSUP), 'rb') as f: \n",
    "        model_unsup = load(f)\n",
    "    return model_sup,model_unsup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43128b58",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5dbfb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:05.557024Z",
     "start_time": "2021-06-08T03:37:05.444560Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def full_pipeline(text,supervised_model,unsupervised_model):\n",
    "    model_sup = supervised_model\n",
    "    model_unsup = unsupervised_model\n",
    "    \n",
    "    df = DataFrame(text,index=[0],columns=['tweet_text'])\n",
    "    df['len'] = df['tweet_text'].str.split().apply(len)\n",
    "    df['clean_tweet'] = df['tweet_text'].apply(clean_tweet)\n",
    "    #All hashtags or mentions\n",
    "    df['#_or_@'] = df['tweet_text'].apply(lambda x: ' '.join(findall(r'[@|#]([\\S]+)',x)))\n",
    "    #Split them like \"VamosAmerica\" to \"vamos america\", \"UFC\" stands the same\n",
    "    df['#_or_@'] = df['#_or_@'].apply(lambda x:sub(r'([A-Z])(?![A-Z])',lambda a:' '+a.group(1).lower(),x).strip())\n",
    "\n",
    "    df['length'] = df['tweet_text'].apply(len)\n",
    "    df['relevance'] = df['clean_tweet'].apply(len)/(df['length']+1e-10)\n",
    "\n",
    "    df['n_mentions'] = df['tweet_text'].apply(lambda x: len(findall('@',x)))\n",
    "    df['n_hashtags'] = df['tweet_text'].apply(lambda x: len(findall('#',x)))\n",
    "    df['n_links'] = df['tweet_text'].apply(lambda x: len(findall('http',x)))\n",
    "    df['n_uppercase'] = df['tweet_text'].apply(lambda x: len(findall('[A-Z]',x)))\n",
    "\n",
    "    df['p_mentions'] = df['n_mentions'] / df['len']\n",
    "    df['p_hashtags'] = df['n_hashtags'] / df['len']\n",
    "    df['p_links'] = df['n_links'] / df['len']\n",
    "    df['p_uppercase'] = df['n_uppercase'] /df['length']\n",
    "\n",
    "    df['n_len_p_word'] = df['length'] / df['len']\n",
    "    df['lpw_clean'] = df['clean_tweet'].apply(len) / df['len']\n",
    "\n",
    "    df['tot_text'] = df['#_or_@']+\" \"+df['clean_tweet']\n",
    "    \n",
    "    X = df[['tot_text', 'len', 'length', 'relevance', 'n_mentions', 'n_hashtags',\n",
    "            'n_links', 'n_uppercase', 'p_mentions', 'p_hashtags', 'p_links',\n",
    "            'p_uppercase', 'n_len_p_word', 'lpw_clean']].copy()\n",
    "    \n",
    "    output = {'time_stamp':f'{datetime.now().strftime(\"%d/%m/%YT%H:%M\")}',\n",
    "              'team_name':'Untitled'}\n",
    "    aux_dict = {}\n",
    "    for x,y in zip(model_sup.classes_,model_sup.predict_proba(X)[0]):\n",
    "        aux_dict[x] = round(y,3)\n",
    "    rename_dict = {'proba_positive': 'POSITIVE', \n",
    "                   'proba_negative': 'NEGATIVE', \n",
    "                   'proba_neutral': 'NEUTRAL', \n",
    "                   'proba_mixed': 'MIXED'}\n",
    "    for x,y in rename_dict.items():\n",
    "        output[x] = aux_dict[rename_dict[x]]\n",
    "    \n",
    "    output['class'] = model_sup.predict(X)[0]\n",
    "    \n",
    "    \n",
    "    var_unsup = ['len', 'length', 'relevance', 'n_mentions', 'n_hashtags',\n",
    "                 'n_links', 'n_uppercase', 'p_mentions', 'p_hashtags', 'p_links',\n",
    "                 'p_uppercase', 'n_len_p_word', 'lpw_clean']\n",
    "    \n",
    "    var_unsup =  append(df[var_unsup].values,[aux_dict['NEUTRAL'],aux_dict['NEGATIVE'],\n",
    "                                                 aux_dict['POSITIVE'],aux_dict['MIXED']])\n",
    "    \n",
    "    cluster_dict = {1:'Indirectas',2:'Adictos al #',3:'Spam',4:'Haters'}\n",
    "    \n",
    "    output['cluster'] = cluster_dict[model_unsup.predict(array((var_unsup,)))[0]]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ecda3b",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3878a68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T03:37:07.929458Z",
     "start_time": "2021-06-08T03:37:05.573865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'time_stamp': '07/06/2021T22:37',\n",
       " 'team_name': 'Untitled',\n",
       " 'proba_positive': 0.667,\n",
       " 'proba_negative': 0.015,\n",
       " 'proba_neutral': 0.297,\n",
       " 'proba_mixed': 0.021,\n",
       " 'class': 'POSITIVE',\n",
       " 'cluster': 'Adictos al #'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_sup,model_unsup = read_models()\n",
    "text = df[df['sentiment']!='NEUTRAL'].sample()['tweet_text'].values[0]\n",
    "full_pipeline(text,model_sup,model_unsup)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
